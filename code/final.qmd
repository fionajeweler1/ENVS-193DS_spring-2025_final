---
title: "ENVS 193DS Final"
author: "Fiona Jeweler"
date: "2025-06-11"
format:
  html:
    toc: true
    toc-location: left
    theme: cosmo
    number-sections: true
    smooth-scroll: true
    table-scroll: true
    embed-resources: true
---

**Name:** Fiona Jeweler  
**Date:** June 11th, 2025

```{r Load packages and data, include=TRUE, message = FALSE, warning = FALSE}
#Loading packages 
library(tidyverse)
library(readr)
library(janitor)
library(ggplot2)
library(lubridate)
library(here)
library(DHARMa)
library(MuMIn)
library(broom)
library(performance)
library(knitr)
library(MuMIn)

#Read in sea surface temperature dataset
sst <- read_csv(here::here("Data", "SST_update2023.csv"))

# Read in the Swift Parrot nest box data
nest_boxes <- read_csv(here("Data", "occdist.csv"))
# Clean column names for consistency
nest_boxes <- nest_boxes |> 
  clean_names()
```

# Problem 1. Research Writing

## a. 
In part 1, the researcher likely used a correlation test (such as a Pearson's correlation coefficient), depending on the distributiuon of the data. I can infer this because of the phrasing "correlation between distance from headwater (km) and annual total nitrogen load (kg year⁻¹).” In part 2, they likely used a one-way ANOVA test to decide whether the mean nitrogen loads differ among the five sources: urban land, atmospheric deposition, fertilizer, wastewater treatment, and grasslands. This is suggested by the phrasing “difference in average nitrogen load between sources.”

## b. 
To provide better context for part 2, my co-worker could include:

### 1: 
Tukey's HSD - since the ANOVA tells us only that at least one group differs from the others, a post-hoc test would tell us which specific source categories differ significantly in nitrogen load. This information adds clarity to the biological interpretation and lets us know where intervention measures might be needed. 

### 2: 
Cohen's f: Knowing the p-value tells us whether the result is statistically significant, but not how meaningful the difference is. An effect size like a cohen's f test could help us evaluate the magnitude of the difference in nitrogen load between sources and whether it is ecologically significant. 

## c. 

### Part 1 revised: 
We found that annual total nitrogen load increased with distance from the river’s headwaters, suggesting downstream areas receive more nitrogen, potentially due to cumulative runoff. (Pearson's correlation coefficient, r = correlation coefficient, p = 0.03, α = significance level). 

### Part 2 revised: 
We found that average nitrogen load differed significantly among sources, suggesting some sources (like  fertilizer or wastewater) may contribute more nitrogen to the system than others. (One-way ANOVA, F = test statistic, df = degrees of freedom, p = 0.02, α = significance level). 

# Problem 2. Data Visualization 

## a. 
```{r CLean Data, include=TRUE, message = FALSE, warning = FALSE}
# Clean and summarize SST data to match required structure
sst_clean <- sst |> 
  mutate(date = as.Date(date)) |> 
  filter(year(date) >= 2018 & year(date) <= 2023) |> 
  mutate(
    year = factor(year(date)),
    month = factor(month(date, label = TRUE, abbr = TRUE), 
                   levels = month.abb, ordered = TRUE)
  ) |> 
  group_by(year, month) |> 
  summarise(mean_monthly_sst = mean(temp, na.rm = TRUE)) |> 
  ungroup()

# Show 5 random rows
slice_sample(sst_clean, n = 5)

# Show structure of the data
str(sst_clean)
```

## b. 
```{r Create visualization, include=TRUE, message = FALSE, warning = FALSE}

# Filter the subset of years shown in the original figure
sst_clean |> 
  filter(year %in% c("2018", "2019", "2020", "2021", "2022", "2023")) |> 
  ggplot(aes(x = month, y = mean_monthly_sst, group = year, color = year)) +
  
  # Two geometries: lines and points
  geom_line(size = 1) +
  geom_point(size = 2) +
  
  # Y-axis label
  scale_y_continuous(limits = c(13, 20)) +
  
  # Custom color scale: single color gradient from light to dark (e.g., blue)
  scale_color_manual(
    values = c(
      "2018" = "#c6dbef",
      "2019" = "#9ecae1",
      "2020" = "#6baed6",
      "2021" = "#4292c6",
      "2022" = "#2171b5",
      "2023" = "#084594"
    )
  ) +

  # Axis and legend labels
  labs(
    x = "Month",
    y = "Mean monthly sea surface temperature (°C)",
    color = "Year"
  ) +

  # Theme settings for panel border and background
  theme_minimal(base_size = 12) +
  theme(
    legend.position = c(0.15, 0.75),          # Legend inside panel
    legend.background = element_rect(fill = "white", color = "black"),
    panel.border = element_rect(color = "black", fill = NA, linewidth = 1),
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 13),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

# Part 3. Data Analysis

## a. 
In this dataset, the 1s and 0s represent nest box occupancy: a 1 indicates the box was occupied by a specific species (or was empty), and a 0 means it was not. The columns correspond to species, Swift Parrot (sp), Common Starling (cs), Tree Martin (tm), and e for empty boxes. 

## b. 
The Swift Parrot is the critically endangered target species that the nest boxes were designed to support. On the other hand, Common Starlings (an introduced species) and Tree Martins (a native competitor) are non-target species who may exploit the nest boxes, potentially impacting the conservation success for the Swift Parrots. 

## c. 
The two seasons refer to the 2016 breeding season when newly deployed nest boxes were first installed, and 2019 when the same boxes had been left in place for multiple years. These seasons compare occupancy shortly after they were deployed versus with more established boxes, showing that the Common Starlings and Tree Martins used the older boxes more extensively than the newly deployed ones. 

## d. 
```{r, message = FALSE, warning = FALSE}
# Clean data 
nest_boxes <- nest_boxes |> 
  mutate(
    season = factor(season),              # season as a factor
    edge_distance = as.numeric(edge_distance)  # ensure edge_distance is numeric
  )

# Model 1: Null model
model_1 <- glm(sp ~ 1, data = nest_boxes, family = "binomial")

# Model 2: Saturated model with interaction
model_2 <- glm(sp ~ season * edge_distance, data = nest_boxes, family = "binomial")

# Model 3: Season only
model_3 <- glm(sp ~ season, data = nest_boxes, family = "binomial")

# Model 4: Distance only
model_4 <- glm(sp ~ edge_distance, data = nest_boxes, family = "binomial")

# Create a model overview table
model_table <- tibble::tibble(
  `Model number` = c("Model 1", "Model 2", "Model 3", "Model 4"),
  `Season` = c("", "X", "X", ""),
  `Distance to forest edge` = c("", "X", "", "X"),
  `Predictor list` = c(
    "no predictors (null model)",
    "season and distance with interaction (saturated model)",
    "season only",
    "distance only"
  )
)

# Display the table nicely in HTML
kable(model_table, align = "c")
```

## e. 
```{r, echo = TRUE, message = FALSE, warning = FALSE}

# Run all models (no output shown)
model_1 <- glm(sp ~ 1, data = nest_boxes, family = "binomial")                            # Null model
model_2 <- glm(sp ~ season * edge_distance, data = nest_boxes, family = "binomial")       # Saturated model with interaction
model_3 <- glm(sp ~ season, data = nest_boxes, family = "binomial")                       # Main effect of season
model_4 <- glm(sp ~ edge_distance, data = nest_boxes, family = "binomial")                # Main effect of distance

```

## f. 
```{r model1-diagnostics, message = FALSE, warning = FALSE}
# Simulate residuals for the null model
sim_1 <- simulateResiduals(fittedModel = model_1)

# Plot the residual diagnostics without the default title and text
plot(sim_1, main = "", annotate = FALSE)

```

```{r model2-diagnostics, message = FALSE, warning = FALSE}
# Simulate residuals for the model with interaction between season and edge_distance
sim_2 <- simulateResiduals(fittedModel = model_2)

# Plot the residual diagnostics without the default title and text
plot(sim_2, main = "", annotate = FALSE)

```

```{r model3-diagnostics, message = FALSE, warning = FALSE}
# Simulate residuals for the model with only season as a predictor
sim_3 <- simulateResiduals(fittedModel = model_3)

# Plot the residual diagnostics without default title and annotation text
plot(sim_3, main = "", annotate = FALSE)

```

```{r model4-diagnostics, message = FALSE, warning = FALSE}
# Simulate residuals for the model with only edge_distance as a predictor
sim_4 <- simulateResiduals(fittedModel = model_4)

# Plot the residual diagnostics without default annotations
plot(sim_4, main = "", annotate = FALSE)

```

## g. 
```{r, message = FALSE, warning = FALSE}
# Compare AIC values for all models
aic_results <- AIC(model_1, model_2, model_3, model_4)

# View the results
print(aic_results)
```

The best model as determined by Akaike’s Information Criterion (AIC) was model 2, the saturated model, which included both season and edge distance as predictors, as well as their interaction. This model had the lowest AIC value (226.85), indicating it best balances model fit and complexity. The response variable in this model was nest box occupancy by Swift Parrots (1 = occupied, 0 = not occupied).

## h. 
```{r, message = FALSE, warning = FALSE}
# Generate prediction data across edge distances for each season
new_data <- expand.grid(
  edge_distance = seq(min(nest_boxes$edge_distance), max(nest_boxes$edge_distance), length.out = 100),
  season = levels(nest_boxes$season)
)

# Add predictions and standard errors from model_2
predictions <- predict(model_2, newdata = new_data, type = "link", se.fit = TRUE)
new_data$fit <- predictions$fit
new_data$se <- predictions$se.fit

# Calculate predicted probabilities and 95% confidence intervals
new_data$predicted <- plogis(new_data$fit)
new_data$lower <- plogis(new_data$fit - 1.96 * new_data$se)
new_data$upper <- plogis(new_data$fit + 1.96 * new_data$se)

# Plotting
ggplot(nest_boxes, aes(x = edge_distance, y = sp, color = season)) +
  geom_point(alpha = 0.5, position = position_jitter(height = 0.02)) +
  geom_line(data = new_data, aes(x = edge_distance, y = predicted, color = season), size = 1.2) +
  geom_ribbon(
    data = new_data,
    inherit.aes = FALSE,
    aes(x = edge_distance, ymin = lower, ymax = upper, fill = season),
    alpha = 0.3
  ) +
  scale_color_manual(values = c("darkorange", "deepskyblue")) +
  scale_fill_manual(values = c("darkorange", "deepskyblue")) +
  labs(
    title = "Predicted Probability of Swift Parrot Nest Box Occupancy",
    x = "Distance to Forest Edge (meters)",
    y = "Predicted Occupancy Probability",
    color = "Season",
    fill = "Season"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    panel.grid = element_blank(),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

```

## i. 
Figure 1. Predicted Probability of Swift Parrot Nest Box Occupancy by Distance from Forest Edge and Year.
This figure shows model-predicted probabilities of Swift Parrot (Lathamus discolor) nest box occupancy as a function of distance from the forest edge in 2016 and 2019. Solid lines represent predictions from a binomial GLM with an interaction between year (season) and distance, and shaded ribbons indicate 95% confidence intervals. Points represent the observed occupancy data (1 = occupied, 0 = unoccupied), jittered for visibility. Occupancy probability declines with increasing distance, with higher probabilities closer to the forest edge in 2016 than in 2019.
Data source: Stojanovic, Dejan et al. (2021). Do nest boxes breed the target species or its competitors? A case study of a critically endangered bird [Dataset]. Dryad. https://doi.org/10.5061/dryad.83bk3j9sb 

## j. 
```{r, message = FALSE, warning = FALSE}
# Create a new dataframe for prediction at 0 m and 900 m for each season
new_data <- expand.grid(
  season = factor(c(2016, 2019), levels = levels(nest_boxes$season)),
  edge_distance = c(0, 900)
)

# Predict probabilities from the best model (saturated model)
predictions <- predict(model_2, newdata = new_data, type = "response", se.fit = TRUE)

# Calculate 95% confidence intervals on the logit scale and transform back to probabilities
new_data$fit <- predictions$fit
new_data$se.fit <- predictions$se.fit
new_data$lower <- plogis(qlogis(new_data$fit) - 1.96 * new_data$se.fit)
new_data$upper <- plogis(qlogis(new_data$fit) + 1.96 * new_data$se.fit)

# Display the result
new_data
```

## k. 
The predicted probability of Swift Parrot nest box occupancy was highest at the forest edge (0 m) in 2016 (approximately 54%) and lowest at 900 m from the forest edge in both seasons (around 9%). Between seasons, predicted occupancy at the edge dropped in 2019 to about 24%, suggesting reduced use over time. As distance from the forest edge increased, the likelihood of occupancy consistently decreased, especially in 2016. This pattern suggests that Swift Parrots prefer nest boxes near forest edges, likely because these areas provide better access to foraging resources or cover. In contrast, Common Starlings showed the opposite trend in the study, becoming more dominant in boxes farther from the forest edge, especially as the boxes aged, highlighting the biological importance of carefully managing box placement to avoid unintentional support of invasive competitors.

# Part 4: 

## a. 
I made a lot of changes to my affective visualization after workshop 9 so here is the updated version:
![Affective visualization of sleep onset time by day and activity goal](Rplot.png)
How are the visualizations different from each other in the way you have represented your data?

My affective visualization from Homework 3 is more about emotion and aesthetics — I used color and borders to show patterns in how fast I fell asleep and whether I met my activity goal. The exploratory visuals from Homework 2 were more straightforward: a boxplot and a scatterplot, both meant to show relationships clearly and numerically. The affective one was more artistic, while the others were made to analyze.

What similarities do you see between all your visualizations?

All of them are trying to answer the same basic question: does more activity help me fall asleep faster? Whether I showed it through colored squares or dots on a plot, they all look at that connection between physical movement and sleep onset.

What patterns do you see in each visualization? Are these different between visualizations? If so, why? If not, why not?

In the affective plot, I noticed that the lighter blue squares (faster sleep onset) often had gold borders, meaning I hit my step goal on those days. In the boxplot, I saw a lower median fall-asleep time on goal days, which kind of backs that up. And in the scatterplot, there was a small downward trend — not super strong, but it did look like more steps led to falling asleep faster. So the pattern was pretty consistent across all three, just shown in different ways.

What kinds of feedback did you get during week 9 in workshop or from the instructors? How did you implement or try those suggestions?

Someone in workshop mentioned I should label my key more clearly, so I made sure to add a better title to the color scale for the affective visualization. I also changed the way I framed the borders to be more visually consistent. I didn’t add numbers to the heatmap though — I decided to keep it feeling more intuitive instead of statistical since that was kind of the whole point of the piece.

## b. 
I was there!